# This codes are from https://ohenziblog.com/streamlit_cloud_for_selenium/
# Thanks to the author for great help.
import os
os.system("playwright install")

import streamlit as st
from selenium import webdriver
# from webdriver_manager.chrome import ChromeDriverManager
# from selenium.webdriver.chrome import service as fs
from selenium.webdriver import ChromeOptions
# from webdriver_manager.core.utils import ChromeType
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import Select
from selenium.webdriver.chrome.service import Service
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import requests
import numpy as np
import extra_streamlit_components as stx
from io import BytesIO
from stqdm import stqdm
from playwright.sync_api import Playwright, sync_playwright, expect
from datetime import datetime
from pytz import timezone, utc
from stqdm import stqdm
import streamlit_authenticator as stauth
import json
from playwright.sync_api import TimeoutError as PlaywrightTimeoutError
from playwright.sync_api import Error as PlaywrightError
from pathlib import Path


st.title("Scraping in streamlit cloud")

press_button = st.button("Scraping")

URL = 'https://www.kofiabond.or.kr/websquare/websquare.html?w2xPath=/xml/bondint/lastrop/BISLastAskPrcDay.xml&divisionId=MBIS01010010000000&divisionNm=%25EC%259D%25BC%25EC%259E%2590%25EB%25B3%2584&tabIdx=1&w2xHome=/xml/&w2xDocumentRoot='

options = ChromeOptions()
# íŒì—…ì°½ ì°¨ë‹¨
options.add_experimental_option("excludeSwitches", ["disable-popup-blocking"])
options.add_argument("--headless")
options.add_argument('--disable-gpu')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--remote-debugging-port=9222')

# CHROMEDRIVER = ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install()
# service = fs.Service(CHROMEDRIVER)
service = Service()

#datatype: 0-í™˜ììˆ˜, 1-ì´ì‚¬ìš©ëŸ‰, 2-ì§„ë£Œê¸ˆì•¡
#tabletype: 0-ì„±/5ì„¸ì—°ë ¹ë‹¨ìœ„ë³„, 1-ì…ì›ì™¸ë˜ë³„, 2-ìš”ì–‘ê¸°ê´€ì¢…ë³„ / 10-KCDì½”ë“œ ì„±/5ì„¸ì—°ë ¹ë‹¨ìœ„ë³„(3~4ë‹¨ ìë™ êµ¬ë¶„)
def scrapToDf(hiraStr, hiraCode, datatype, tabletype):
    patternYr = '[0-9]+ë…„'

    if tabletype == 0:
        patternNum = '[0-9]+_[0-9]+ì„¸|[0-9]+ì„¸ë¯¸ë§Œ|[0-9]+ì„¸ì´ìƒ'
    elif tabletype == 1:
        patternNum = 'ì…ì›$|ì™¸ë˜$'
    elif tabletype == 2:
        patternNum = '[ê°€-í£]{2,}'
    elif tabletype == 10:
        patternNum = '[0-9]+_[0-9]+ì„¸|[0-9]+ì„¸ë¯¸ë§Œ|[0-9]+ì„¸ì´ìƒ'
    else:
        patternNum = '[0-9]+_[0-9]+ì„¸|[0-9]+ì„¸ë¯¸ë§Œ|[0-9]+ì„¸ì´ìƒ'

    count = 0
    flag = False

    # ë°ì´í„° ì—°ë„ ì²´í¬
    Yr = []
    for itm in hiraStr:
        result = re.match(patternYr, itm)
        if result:
            Yr.append(itm)
            count = count + 1

    if tabletype == 0:
        Yr.insert(0, 'Age')
        Yr.insert(0, 'Gender')
        Yr.insert(0, 'Code')
    elif tabletype == 1:
        Yr.insert(0, 'In/Outpatient')
        Yr.insert(0, 'Gender')
        Yr.insert(0, 'Code')
    elif tabletype == 2:
        Yr.insert(0, 'Hospital Type')
        Yr.insert(0, 'Code')
    elif tabletype == 10:
        Yr.insert(0, 'Age')
        Yr.insert(0, 'Gender')
        Yr.insert(0, 'Code')
    else:
        Yr.insert(0, 'Age')
        Yr.insert(0, 'Gender')
        Yr.insert(0, 'Code')

    # ì—¬ê¸°ì—ì„œ ì¶”ê°€í•  í•­ëª© ê°¯ìˆ˜(í™˜ììˆ˜, ì‚¬ìš©ëŸ‰, ê¸ˆì•¡)ë§Œí¼ ì»¬ëŸ¼ì„ ëŠ˜ë ¤ì¤˜ì•¼ í•¨
    df = pd.DataFrame(columns=Yr)

    flag = False
    df_row = []
    df_data = []

    for itm in hiraStr:

        if tabletype != 2 and (itm == 'ë‚¨' or itm == 'ì—¬'):
            gender = itm
            df_row = [hiraCode, gender]
        elif tabletype == 2:
            if 'ë³‘ì›' in itm or 'ì˜ì›' in itm:
                df_row = [hiraCode]

        # result: patternNum ê³¼ ì •ê·œí‘œí˜„ì‹ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸, "ì»¬ëŸ¼í•­ëª©" ì¸ì§€ "ë°ì´í„°ê°’" ì¸ì§€ êµ¬ë¶„í•˜ê¸° ìœ„í•¨
        # flag: ë¼ì¸ì´ ëë‚¬ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•¨, False ê°€ ìƒˆë¡œìš´ Row ì˜ ì‹œì‘ì„ ì˜ë¯¸
        if tabletype != 2:
            result = re.match(patternNum, itm)
        elif 'ë³‘ì›' in itm or 'ì˜ì›' in itm:
            result = True
            hospType = itm
        else:
            result = False

        # result = True ì´ë©´, df_row ì— "ì»¬ëŸ¼í•­ëª©" ì¶”ê°€ & flag = True ì„¸íŒ…
        # result = False / flag = True ì´ë©´, df_data ì— "ë°ì´í„°ê°’" ì¶”ê°€
        if result:
            #print(itm)
            flag = True
            df_row.append(itm)
        elif flag == True:
            df_data.append(itm.replace('-', '0'))

        # í–‰ ë„˜ì–´ê°ˆë•Œ ì´ˆê¸°í™”
        # count: ë°ì´í„° ì—°ë„ ê°¯ìˆ˜
        # numCol: ì—°ë„ë³„ ë°ì´í„° ì»¬ëŸ¼ ê°¯ìˆ˜
        if tabletype < 10:
            numCol = 3
        else:
            numCol = 5
        
        # print(itm, result, flag, df_row, df_data)

        if len(df_data) / numCol == count :
            flag = False
            df_row.extend(df_data[datatype::numCol])
            df.loc[len(df)] = df_row
            if tabletype != 2:
                df_row = [hiraCode, gender]
            else:
                df_row = [hiraCode]

            df_data = []

    return df

def take_HIRA_data(code, datatype, tabletype):

    success = False
    result_df = pd.DataFrame()

    while not success:
        try:
            # HIRA ì˜ë£Œí†µê³„ì •ë³´ ì‚¬ì´íŠ¸ ë‚´ë¶€ì˜ iframe ë¶€ë¶„ì— ëŒ€í•œ URL í˜¸ì¶œ
            driver = webdriver.Chrome(options=options,
                                      service=service
                                      )

            if tabletype == 0:
                # ìˆ˜ê°€ì½”ë“œ ì„±ë³„/ì—°ë ¹5ì„¸êµ¬ê°„ë³„
                url = 'http://olapopendata.hira.or.kr/analysis/desktop/poc2.jsp#report_id=cc2e8d5a-fd4146ce&PARAM1=1' + code
            elif tabletype == 1:            
                # ìˆ˜ê°€ì½”ë“œ ì…ì›ì™¸ë˜ë³„
                url = 'http://olapopendata.hira.or.kr/analysis/desktop/poc2.jsp#report_id=a51b2db5-2aea4cfd&PARAM1=1' + code
            elif tabletype == 2:
                # ìˆ˜ê°€ì½”ë“œ ìš”ì–‘ê¸°ê´€ì¢…ë³„
                url = 'http://olapopendata.hira.or.kr/analysis/desktop/poc2.jsp#report_id=60039d2b-9d6746b0&PARAM1=1' + code
            elif tabletype == 10:
                # KCD ì½”ë“œ ì„±ë³„/ì—°ë ¹5ì„¸êµ¬ê°„ë³„ (3ë‹¨ / 4ë‹¨)
                if len(code) == 3:
                    url = 'http://olapopendata.hira.or.kr/analysis/desktop/poc2.jsp#report_id=a576a04f-79a44e41&PARAM1=A' + code
                else:
                    url = 'http://olapopendata.hira.or.kr/analysis/desktop/poc2.jsp#report_id=8edbc258-9b01430b&PARAM1=A' + code
            else:
                # ìˆ˜ê°€ì½”ë“œ ì„±ë³„/ì—°ë ¹5ì„¸êµ¬ê°„ë³„
                url = 'http://olapopendata.hira.or.kr/analysis/desktop/poc2.jsp#report_id=cc2e8d5a-fd4146ce&PARAM1=1' + code

            driver.get(url)

            element = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH, '//*[@id="ext-gen1645"]/table/tbody/tr/td/div[6]/select')))

            # ì‹œì‘ë…„ë„ 2010ë…„(ê¸°ë³¸ê°’ 2015ë…„)ìœ¼ë¡œ ë³€ê²½
            select = Select(driver.find_element(By.XPATH, '//*[@id="ext-gen1645"]/table/tbody/tr/td/div[6]/select'))
            select.select_by_value('2010')

            time.sleep(10)

            select = Select(driver.find_element(By.XPATH, '//*[@id="ext-gen1645"]/table/tbody/tr/td/div[8]/select'))
            select.select_by_value('2022')

            driver.set_window_size(15360, 8640)

            element = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CLASS_NAME, 'dt-btn-search')))

            # ì¡°íšŒ ë²„íŠ¼ í´ë¦­
            btn_search = driver.find_element(By.CLASS_NAME, 'dt-btn-search')
            btn_search.click()
            
            element = WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CLASS_NAME, 'm-cell-text')))
            data_grid = driver.find_elements(By.CLASS_NAME, 'm-cell-text')

            result = [e.text for e in data_grid if e.text != '']

            if result == []:
                print(f'There is no data for {code}.')
            else:
                result_df = scrapToDf(result, code, datatype, tabletype)

            success = True

            driver.close()
            driver.quit()

        except Exception as e:
            driver.close()
            driver.quit()
            pass

    return result_df

def call_HIRA():
    with st.spinner('Wait for it...'):
        df = take_HIRA_data(code=code, datatype=datatype, tabletype=tabletype)

    st.write(df)

def call_HIRA_new(datatype, code, fstYr, lstYr):

    if datatype == 1:
        # ì§ˆë³‘ ì†Œë¶„ë¥˜(3ë‹¨ ìƒë³‘) í†µê³„
        url = f"https://opendata.hira.or.kr/op/opc/olap3thDsInfoTab2.do?olapCd=A{code}&tabGubun=Tab2&gubun=R&sRvYr={fstYr}&eRvYr={lstYr}&sDiagYm=&eDiagYm=&sYm=&eYm="
    elif datatype == 2:
        # ì§ˆë³‘ ì„¸ë¶„ë¥˜(4ë‹¨ ìƒë³‘) í†µê³„
        url = f"https://opendata.hira.or.kr/op/opc/olap4thDsInfoTab2.do?olapCd=A{code}&tabGubun=Tab2&gubun=R&sRvYr={fstYr}&eRvYr={lstYr}&sDiagYm=&eDiagYm=&sYm=&eYm="
    elif datatype == 3:
        # ì§„ë£Œí–‰ìœ„(ê²€ì‚¬/ìˆ˜ìˆ  ë“±) í†µê³„
        url = f"https://opendata.hira.or.kr/op/opc/olapDiagBhvInfoTab2.do?olapCd=1{code}&tabGubun=Tab2&gubun=R&sRvYr={fstYr}&eRvYr={lstYr}&sDiagYm=&eDiagYm=&sYm=&eYm="
    
    res = requests.get(url)
    soup = BeautifulSoup(res.text, 'lxml')
    result = soup.find(attrs={'class':'tblType02 data webScroll'})

    df = pd.read_html(str(result))[0]
    df = df.dropna(axis=0)

    df.columns = ['_'.join(col).strip() for col in df.columns.values]

    column = []
    for col in df.columns:
        if 'Unnamed' in col:
            col = col.split('_')[3]
        column.append(col)

    df.columns = column
    df = df.melt(id_vars=['í•­ëª©', 'ì„±ë³„êµ¬ë¶„', 'ì‹¬ì‚¬ë…„ë„_ì—°ë ¹êµ¬ë¶„5ì„¸'])

    df[['ì‹¬ì‚¬ë…„ë„', 'í•­ëª©êµ¬ë¶„']] = df['variable'].str.split('_', expand=True)
    df.rename(columns={'ì‹¬ì‚¬ë…„ë„_ì—°ë ¹êµ¬ë¶„5ì„¸':'ì—°ë ¹êµ¬ë¶„'}, inplace=True)
    df.drop(['variable'], axis='columns', inplace=True)
    df = df[['í•­ëª©', 'ì‹¬ì‚¬ë…„ë„', 'í•­ëª©êµ¬ë¶„', 'ì„±ë³„êµ¬ë¶„', 'ì—°ë ¹êµ¬ë¶„', 'value']]
    
    df['value'] = pd.to_numeric(df['value'], errors='coerce')
    df['value'] = df['value'].fillna(0)

    return df

def to_excel(df):
    output = BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    df.to_excel(writer, index=False, sheet_name='Sheet1')
    writer.close()

    processed_data = output.getvalue()

    return processed_data


def run_kofiabond(playwright: Playwright):

    browser = playwright.chromium.launch(headless=True)
    context = browser.new_context()
    page = context.new_page()
    page.goto("https://www.kofiabond.or.kr/websquare/websquare.html?w2xPath=/xml/bondint/lastrop/BISLastAskPrcDay.xml&divisionId=MBIS01010010000000&divisionNm=%25EC%259D%25BC%25EC%259E%2590%25EB%25B3%2584&tabIdx=1&w2xHome=/xml/&w2xDocumentRoot=")
    page.get_by_role("link", name="ì¡°íšŒ").click()

    content = page.content()
    
    soup = BeautifulSoup(content, 'html5lib').find_all('table', attrs={'id':'grdMain_body_table'})

    df = pd.read_html(str(soup[0]))[0]

    context.close()
    browser.close()

    return df

def run_lottery(playwright: Playwright):

    id = st.secrets["lottery"]["id"]
    pw = st.secrets["lottery"]["password"]

    KST = timezone('Asia/Seoul')
    now = datetime.utcnow()

    SeoulTime = utc.localize(now).astimezone(KST)
    ThisYr0101 = SeoulTime.strftime("%Y0101")
    curDate = SeoulTime.strftime("%Y%m%d")

    browser = playwright.chromium.launch(headless=True)
    context = browser.new_context()
    page = context.new_page()

    page.goto("https://dhlottery.co.kr/user.do?method=login&returnUrl=")
    page.get_by_placeholder("ì•„ì´ë””").click()
    page.get_by_placeholder("ì•„ì´ë””").fill(id)
    page.get_by_placeholder("ì•„ì´ë””").press("Tab")
    page.get_by_placeholder("ë¹„ë°€ë²ˆí˜¸").fill(pw)
    page.get_by_placeholder("ë¹„ë°€ë²ˆí˜¸").press("Tab")
    page.get_by_role("group", name="LOGIN").get_by_role("link", name="ë¡œê·¸ì¸").press("Enter")

    time.sleep(2)
    page.goto("https://dhlottery.co.kr/userSsl.do?method=myPage")

    page.get_by_role("link", name="êµ¬ë§¤/ë‹¹ì²¨").click()
    page.get_by_role("link", name="1ê°œì›”").click()
    page.get_by_role("link", name="ì¡°íšŒ", exact=True).click()
    page.get_by_role("link", name="ì¡°íšŒ", exact=True).click()
    page.get_by_role("link", name="ì¡°íšŒ", exact=True).click()
    page.goto(f"https://dhlottery.co.kr/myPage.do?method=lottoBuyList&searchStartDate={ThisYr0101}&searchEndDate={curDate}&lottoId=&nowPage=1")
    
    content = page.content()

    soup = BeautifulSoup(content, 'html5lib').find_all('table', attrs={'class':'tbl_data tbl_data_col'})

    df = pd.read_html(str(soup[0]))[0]

    context.close()
    browser.close()

    return df

def run_lottery_all(playwright: Playwright) -> pd.DataFrame:
    id = st.secrets["lottery"]["id"]
    pw = st.secrets["lottery"]["password"]

    KST = timezone('Asia/Seoul')
    now = datetime.utcnow()

    SeoulTime = utc.localize(now).astimezone(KST)
    curDate = SeoulTime.strftime("%Y%m%d")

    browser = playwright.chromium.launch(headless=True)
    context = browser.new_context()
    page = context.new_page()

    page.goto("https://dhlottery.co.kr/user.do?method=login&returnUrl=")
    page.get_by_placeholder("ì•„ì´ë””").click()
    page.get_by_placeholder("ì•„ì´ë””").fill(id)
    page.get_by_placeholder("ì•„ì´ë””").press("Tab")
    page.get_by_placeholder("ë¹„ë°€ë²ˆí˜¸").fill(pw)
    page.get_by_placeholder("ë¹„ë°€ë²ˆí˜¸").press("Tab")
    page.get_by_role("group", name="LOGIN").get_by_role("link", name="ë¡œê·¸ì¸").press("Enter")

    time.sleep(2)

    # ë§ˆì§€ë§‰ í˜ì´ì§€ ì°¾ê¸°
    page.goto(f"https://dhlottery.co.kr/myPage.do?method=lottoBuyList&searchStartDate=20200502&searchEndDate={curDate}&lottoId=&nowPage=100000")

    content_end = page.content()
    soup_end = BeautifulSoup(content_end, 'html5lib').find_all('div', attrs={'class':'paginate_common'})
    for pageList in soup_end:
        for pagenum in pageList.find_all('a'):
            lastPageStr = pagenum.text.replace(" ", "")

    lastPageNum = int(lastPageStr) + 1
    print(lastPageNum)

    page.goto("https://dhlottery.co.kr/userSsl.do?method=myPage")

    page.get_by_role("link", name="êµ¬ë§¤/ë‹¹ì²¨").click()
    page.get_by_role("link", name="1ê°œì›”").click()
    page.get_by_role("link", name="ì¡°íšŒ", exact=True).click()
    page.get_by_role("link", name="ì¡°íšŒ", exact=True).click()
    page.get_by_role("link", name="ì¡°íšŒ", exact=True).click()

    df_all = pd.DataFrame()
    
    for i in stqdm(range(1, lastPageNum)):
        page.goto(f"https://dhlottery.co.kr/myPage.do?method=lottoBuyList&searchStartDate=20200502&searchEndDate={curDate}&lottoId=&nowPage={i}")
    # print(page.content())
        content = page.content()
        soup = BeautifulSoup(content, 'html5lib').find_all('table', attrs={'class':'tbl_data tbl_data_col'})

        df = pd.read_html(str(soup[0]))[0]
        df_all = pd.concat([df_all, df])

    # with open('lottery.txt', 'w') as textfile:
    #     textfile.write(page.content())
    
    df_all.to_excel('lottery.xlsx', index=False)

    # ---------------------
    context.close()
    browser.close()

    return df_all

def run_benecafe(playwright):
    user_id = st.secrets["benecafe"]["id"]
    user_pw = st.secrets["benecafe"]["password"]

    browser = playwright.chromium.launch(
        headless=True,
        args=["--no-sandbox", "--disable-dev-shm-usage"]
    )
    context = browser.new_context(ignore_https_errors=True, timezone_id="Asia/Seoul", locale="ko-KR")
    context.set_default_timeout(60_000)  # ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ
    page = context.new_page()

    debug_dir = Path("debug")
    debug_dir.mkdir(exist_ok=True)

    def dump_debug(tag: str):
        try:
            page.screenshot(path=str(debug_dir / f"benecafe_{tag}.png"), full_page=True)
        except Exception:
            pass
        try:
            (debug_dir / f"benecafe_{tag}.html").write_text(page.content(), encoding="utf-8")
        except Exception:
            pass

    try:
        # 1) ë¡œê·¸ì¸ í˜ì´ì§€
        page.goto("https://cert.benecafe.co.kr/member/login?&cmpyNo=AA5", wait_until="domcontentloaded")

        # 2) ì…ë ¥ ë° ë¡œê·¸ì¸ í´ë¦­
        page.get_by_placeholder("ì•„ì´ë””").fill(user_id)
        page.get_by_placeholder("ë¹„ë°€ë²ˆí˜¸").fill(user_pw)
        page.get_by_role("link", name="ë¡œê·¸ì¸", exact=True).click()

        # âŒ page.wait_for_load_state("networkidle")  # <- ì´ ì¤„ì´ ì§€ê¸ˆ ë¬¸ì œì˜ ì›ì¸ì…ë‹ˆë‹¤.

        # 3) ë¡œê·¸ì¸ ì„±ê³µì˜ â€œí™•ì • ì‹ í˜¸â€ë¥¼ ê¸°ë‹¤ë¦¼ (ìš”ì†Œ ê¸°ë°˜)
        page.wait_for_selector('text="ë‚˜ì˜ì •ë³´"', timeout=60_000)

        # 4) íŒì—… ë‹«ê¸° (ìˆìœ¼ë©´)
        close_btn = page.get_by_role("link", name="ë‹«ê¸°")
        if close_btn.count() > 0:
            close_btn.first.click()

        # 5) ë°ì´í„° í˜¸ì¶œì€ page.goto ëŒ€ì‹  context.requestë¡œ (ì„¸ì…˜/ì¿ í‚¤ ê³µìœ )
        #    ë‚ ì§œëŠ” ì˜ˆì‹œ(ê¸°ì¡´ í•˜ë“œì½”ë”© ìœ ì§€). í•„ìš”í•˜ë©´ UI ì…ë ¥ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”.
        api_url = (
            "https://rga.benecafe.co.kr/mywel/getWelfarecardDemandListVer"
            "?crdcoNo=HA&rtnTpCd=&crtcrdProdNo=&ecluCrtcrdRealHhAskYn=N&necluCrtcrdRealHhAskYn=N"
            "&searchStartDate=2025-11-26&searchEndDate=2025-12-26"
            "&applStatCd=00&alreadyApplicationExclustion=&multiCrtcrdRealYn=false&adminPswd="
        )

        resp = context.request.get(api_url, timeout=60_000)
        st.write(f"[benecafe] API status = {resp.status}")

        if resp.status != 200:
            dump_debug(f"api_status_{resp.status}")
            raise RuntimeError(f"Benecafe API returned HTTP {resp.status}")

        return resp.text()

    except PlaywrightTimeoutError:
        dump_debug("timeout")
        raise
    except PlaywrightError:
        dump_debug("playwright_error")
        raise
    finally:
        try:
            context.close()
        except Exception:
            pass
        try:
            browser.close()
        except Exception:
            pass


def run_tmoney(playwright: Playwright):
    id = st.secrets["tmoney"]["id"]
    pw = st.secrets["tmoney"]["password"]

    browser = playwright.chromium.launch(headless=True)
    context = browser.new_context()
    page = context.new_page()
    page.goto("https://pay.tmoney.co.kr/ncs/pct/mtmn/ReadTrprInqr.dev")
    page.get_by_placeholder("ì•„ì´ë””").click()
    page.get_by_placeholder("ì•„ì´ë””").fill(id)
    page.get_by_placeholder("ë¹„ë°€ë²ˆí˜¸").click()
    page.get_by_placeholder("ë¹„ë°€ë²ˆí˜¸").fill(pw)
    page.get_by_title("ë¡œê·¸ì¸í•˜ê¸°").press("Enter")

    time.sleep(2)

    page.get_by_label("ë™ì˜í•¨").click()
    page.get_by_role("combobox", name="ì‚¬ìš©ë‚´ì—­ ì¹´ë“œì„ íƒ").select_option(value="1010010071641385")
    page.get_by_text("ìµœê·¼1ë…„").click()
    page.get_by_role("link", name="ì¡°íšŒ", exact=True).click()

    time.sleep(3)

    content = page.content()
    soup = BeautifulSoup(content, 'html5lib').find_all('table', attrs={'id':'protable'})

    soup_tr1 = str(soup[0])
    soup_tr2 = str(soup[1])
    soup_cs = str(soup[2])

    df_tr1 = pd.read_html(soup_tr1)[0]
    df_tr2 = pd.read_html(soup_tr2)[0]
    df_cs = pd.read_html(soup_cs)[0]

    # ---------------------
    context.close()
    browser.close()

    return df_tr1, df_tr2, df_cs

def benecafe_json_write(html_content: str):
    json_match = re.search(r'<pre>(.*?)</pre>', html_content, re.DOTALL)
    if json_match:
        json_str = json_match.group(1).strip()
        try:
            # JSON íŒŒì‹±
            data = json.loads(json_str)
            
            # ì„±ê³µ ì—¬ë¶€ í™•ì¸
            if data.get("success"):
                # welfarecardDemandList ì¶”ì¶œ
                demand_list = data["resultMap"]["welfarecardDemandList"]
                
                # ê° í•­ëª©ì„ ì˜ˆì˜ê²Œ ì¶œë ¥
                for idx, item in enumerate(demand_list, start=1):
                    st.subheader(f"í•­ëª© {idx}")
                    
                    # ì£¼ìš” ì •ë³´ ì„ íƒì ìœ¼ë¡œ ì¶œë ¥ (null ê°’ì€ ì œì™¸)
                    key_info = {
                        "ì˜ìˆ˜ì¦ ë²ˆí˜¸": item.get("slsRcvNo"),
                        "ì¹´ë“œì‚¬": item.get("crdcoNm"),
                        "ì‚¬ìš© ì¼ì": item.get("crtcrdUseDd"),
                        "ì‚¬ìš© ì‹œê°„": item.get("crtcrdUseHh"),
                        "ì‚¬ìš© ê¸ˆì•¡": item.get("usePrc"),
                        "ì§€ë¶ˆ ì¼ì": item.get("prsnPayDd"),
                        "ìƒì  ì´ë¦„": item.get("mcnsNm"),
                        "ìƒì  ìœ í˜•": item.get("mcnsBntpNm"),
                        "ë“±ë¡ ì—¬ë¶€": item.get("regYn"),
                        "í™˜ë¶ˆ ì—¬ë¶€": item.get("rtnYn"),
                        "ì‹ ì²­ ìƒíƒœ": item.get("cstApplStatNm"),
                        "ì‹ ì²­ ê¸ˆì•¡": item.get("applPrc")
                    }
                    
                    # nullì´ë‚˜ Noneì¸ ê°’ ì œê±°
                    filtered_info = {k: v for k, v in key_info.items() if v is not None}
                    
                    # Markdownìœ¼ë¡œ ì˜ˆì˜ê²Œ ì¶œë ¥
                    for key, value in filtered_info.items():
                        st.markdown(f"**{key}:** {value}")
                    
                    st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€
            else:
                st.error("JSON ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        except json.JSONDecodeError:
            st.error("JSON íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    else:
        st.error("HTMLì—ì„œ JSONì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


chosen_id = stx.tab_bar(data=[
    stx.TabBarItemData(id=1, title="KOFIABOND", description="with Selenium"),
    stx.TabBarItemData(id=2, title="HIRA", description="with Requests"),
    stx.TabBarItemData(id=3, title="KOFIABOND", description="with Playwright"),
    # stx.TabBarItemData(id=4, title="ë³µê¶Œ", description="with Playwright"),
    stx.TabBarItemData(id=5, title="ë³µë¦¬í›„ìƒ", description="with Playwright"),
    # stx.TabBarItemData(id=6, title="tmoney", description="with Playwright"),
], default=1)

placeholder = st.container()

# tab1, tab2 = st.tabs(["KOFIABOND", "HIRA"])

if chosen_id == '1':
# with tab1:
    placeholder.subheader("KOFIABOND")

    if press_button:
        try:
            driver = webdriver.Chrome(options=options,
                                        service=service
                                        )
            driver.get(URL)
            
            element = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.XPATH, '//*[@id="row2"]')))
            soup = driver.find_element(By.XPATH, '//*[@id="grdMain_dataLayer"]').get_attribute('outerHTML')
            soup_bs = BeautifulSoup(soup, 'html5lib')
            df_bond = pd.read_html(str(soup))[0]
            df_bond.columns = df_bond.columns.get_level_values(2)

            placeholder.write(df_bond)

        finally:
            driver.quit()
            # ìŠ¤í¬ë˜í•‘ì´ ì™„ë£Œë˜ì—ˆìŒì„ streamlit ì•±ì— í‘œì‹œ
            placeholder.write("Scraping completed!!!")
elif chosen_id == '2':
# with tab2:
    placeholder.subheader("HIRA")

    help_datatype = "datatype: 1-ì§ˆë³‘ ì†Œë¶„ë¥˜(3ë‹¨ ìƒë³‘), 2-ì§ˆë³‘ ì†Œë¶„ë¥˜(4ë‹¨ ìƒë³‘), 3-ì§„ë£Œí–‰ìœ„(ê²€ì‚¬/ìˆ˜ìˆ  ë“±)"
    datatype_dict = {'ì§ˆë³‘ ì†Œë¶„ë¥˜(3ë‹¨ ìƒë³‘)':1, 'ì§ˆë³‘ ì†Œë¶„ë¥˜(4ë‹¨ ìƒë³‘)':2, 'ì§„ë£Œí–‰ìœ„(ê²€ì‚¬/ìˆ˜ìˆ  ë“±)':3}
    datatype = placeholder.selectbox("Select Data Type", options=datatype_dict.keys(), index=0, help=help_datatype)

    if datatype_dict[datatype] == 1:
        defaultCode = 'C50'
    elif datatype_dict[datatype] == 2:
        defaultCode = 'L400'
    elif datatype_dict[datatype] == 3:
        defaultCode = 'U2233'
    codes = placeholder.text_input("Input HIRA Code", value=defaultCode)
    
    codes = codes.upper().replace(' ', '').split(',')

    fstYr = placeholder.selectbox("Select first year", options=range(2010, 2023), index=0)
    lstYr = placeholder.selectbox("Select last year", options=range(2010, 2023), index=2023-2010-1)

    if press_button:
        df = pd.DataFrame()
        for code in stqdm(codes):
            df_code = call_HIRA_new(datatype_dict[datatype], code, fstYr, lstYr)
            df = pd.concat([df, df_code])

        placeholder.write(df)

        file_name = f'HIRA_{datatype_dict[datatype]}_{code}_{fstYr}_{lstYr}.xlsx'
        df_xlsx = to_excel(df)

        download = st.download_button(
            label="ğŸ“¥ Download Current Result",
            data=df_xlsx,
            file_name=file_name,
            )
elif chosen_id == '3':
    placeholder.subheader("KOFIABOND")
    if press_button:
        with sync_playwright() as playwright:
            df = run_kofiabond(playwright)
        st.write(df)
elif chosen_id == '4':
    placeholder.subheader("ë³µê¶Œ")
    if press_button:
        with sync_playwright() as playwright:
            df = run_lottery(playwright)
        st.write(df)
    if st.button("Extract all"):
        with sync_playwright() as playwright:
            df = run_lottery_all(playwright)
            df_ltr = df.copy()

            df_ltr = df_ltr[(df_ltr['ë³µê¶Œëª…']=='ì—°ê¸ˆë³µê¶Œ720')]
            df_ltr['ë‹¹ì²¨ê¸ˆ'] = df_ltr['ë‹¹ì²¨ê¸ˆ'].str.replace(',', '', regex=True).replace('ì›', '', regex=True).replace('-', '0', regex=True).astype(int)

            total_buy = df_ltr['êµ¬ì…ë§¤ìˆ˜'].sum() * 1000
            count_buy = df_ltr['êµ¬ì…ë§¤ìˆ˜'].count()
            total_won = df_ltr['ë‹¹ì²¨ê¸ˆ'].sum()
            count_won = df_ltr[(df_ltr['ë‹¹ì²¨ê¸ˆ']>0)]['ë‹¹ì²¨ê¸ˆ'].count()

            st.write(f'{total_buy:,.0f}ì› êµ¬ì…í•´ì„œ, {total_won:,.0f}ì› ë‹¹ì²¨')
            st.write(f'ê¸ˆì•¡ê¸°ì¤€: {total_won/total_buy:.1%}, íšŸìˆ˜ê¸°ì¤€: {count_won/count_buy:.1%}')
        
        st.write(df)
elif chosen_id == '5':
    placeholder.subheader("ë³µë¦¬í›„ìƒ")
    if press_button:
        with sync_playwright() as playwright:
            html_content = run_benecafe(playwright)
        benecafe_json_write(html_content)
        # st.write(res)
elif chosen_id == '6':
    placeholder.subheader("í‹°ë¨¸ë‹ˆ")
    tm_pw = st.text_input("Input passkey", type="password")
    stl_pw = st.secrets["general"]["password"]
    if tm_pw == stl_pw:
        st.write("Success!")
        with sync_playwright() as playwright:
            df_tr1, df_tr2, df_cs = run_tmoney(playwright)
        st.write(df_tr1)
        st.write(df_tr2)
        st.write(df_cs)
